# -*- coding: utf-8 -*-
"""Lab08.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NnhxXYWQNO_WU4roAfGJQBC0LGn2MKuw

#Using Bag of Words Frequency (unigram)
"""

import pandas as pd
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

stopWords = set(stopwords.words('english'))

datasets = pd.read_csv('spam.csv')
datasets.head()

datasets.info()

vectorizer = CountVectorizer(stop_words=stopWords)

X = vectorizer.fit_transform(datasets.v2)
y = ['ham' if a=='ham' else 'spam' for a in datasets.v1]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=35)

print("X_train: \n",X_train.toarray())
print("X_test: \n",X_test.toarray())

vectorizer.get_feature_names()

"""##Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

clf = MultinomialNB(alpha = 0.1)
clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)

from sklearn.metrics import precision_score,recall_score

print("Precision is: ",precision_score(y_test,y_pred,average="weighted")*100)
print("Recall is: ",recall_score(y_test,y_pred,average="weighted")*100)

"""##Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier(criterion="gini",max_leaf_nodes=35)

DT.fit(X_train,y_train)

y_pred = DT.predict(X_test)

DT.score(X_test,y_test)*100

print("Precision is: ",precision_score(y_test,y_pred,average="weighted")*100)
print("Recall is: ",recall_score(y_test,y_pred,average="weighted")*100)

"""#Using Bag of Words Frequency (biagram)"""

datasets2 = pd.read_csv('spam.csv')
datasets2.head()

vectorizer2 = CountVectorizer(stop_words=stopWords,ngram_range=(2, 2))

X2 = vectorizer2.fit_transform(datasets2.v2)
y2 = ['ham' if a=='ham' else 'spam' for a in datasets2.v1]

X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size=0.3,random_state=35)

vectorizer2.get_feature_names()

"""##Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

clf = MultinomialNB(alpha = 0.1)
clf.fit(X_train2,y_train2)

y_pred2 = clf.predict(X_test2)

from sklearn.metrics import precision_score,recall_score

print("Precision is: ",precision_score(y_test2,y_pred2,average="weighted")*100)
print("Recall is: ",recall_score(y_test2,y_pred2,average="weighted")*100)

"""##Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT2 = DecisionTreeClassifier(criterion="gini",max_leaf_nodes=35)

DT2.fit(X_train2,y_train2)

y_pred2 = DT2.predict(X_test2)

DT2.score(X_test2,y_test2)*100

print("Precision is: ",precision_score(y_test2,y_pred2,average="weighted")*100)
print("Recall is: ",recall_score(y_test2,y_pred2,average="weighted")*100)

"""#Using TFIDF (unigram)"""

from sklearn.feature_extraction.text import TfidfVectorizer

datasets4 = pd.read_csv('spam.csv')
datasets4.head()

vectorizer4 = TfidfVectorizer(stop_words=stopWords)

X4 = vectorizer4.fit_transform(datasets4.v2)
y4 = ['ham' if a=='ham' else 'spam' for a in datasets4.v1]

X_train4, X_test4, y_train4, y_test4 = train_test_split(X4,y4,test_size=0.3,random_state=35)

vectorizer4.get_feature_names()

"""##Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

clf = MultinomialNB(alpha = 0.1)
clf.fit(X_train4,y_train4)

y_pred4 = clf.predict(X_test4)

print("Precision is: ",precision_score(y_test4,y_pred4,average="weighted")*100)
print("Recall is: ",recall_score(y_test4,y_pred4,average="weighted")*100)

"""##Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT4 = DecisionTreeClassifier(criterion="gini",max_leaf_nodes=35)

DT4.fit(X_train4,y_train4)

y_pred4 = DT4.predict(X_test4)

DT4.score(X_test4,y_test4)*100

print("Precision is: ",precision_score(y_test4,y_pred4,average="weighted")*100)
print("Recall is: ",recall_score(y_test4,y_pred4,average="weighted")*100)



"""#Using TFIDF (biagram)"""

from sklearn.feature_extraction.text import TfidfVectorizer

datasets3 = pd.read_csv('spam.csv')
datasets3.head()

vectorizer3 = TfidfVectorizer(stop_words=stopWords,ngram_range=(2, 2))

X3 = vectorizer3.fit_transform(datasets3.v2)
y3 = ['ham' if a=='ham' else 'spam' for a in datasets3.v1]

X_train3, X_test3, y_train3, y_test3 = train_test_split(X3,y3,test_size=0.3,random_state=35)

vectorizer3.get_feature_names()

"""##Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

clf = MultinomialNB(alpha = 0.1)
clf.fit(X_train3,y_train3)

y_pred3 = clf.predict(X_test3)

print("Precision is: ",precision_score(y_test3,y_pred3,average="weighted")*100)
print("Recall is: ",recall_score(y_test3,y_pred3,average="weighted")*100)

"""##Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT3 = DecisionTreeClassifier(criterion="gini",max_leaf_nodes=35)

DT3.fit(X_train3,y_train3)

y_pred3 = DT3.predict(X_test3)

DT3.score(X_test3,y_test3)*100

print("Precision is: ",precision_score(y_test3,y_pred3,average="weighted")*100)
print("Recall is: ",recall_score(y_test3,y_pred3,average="weighted")*100)